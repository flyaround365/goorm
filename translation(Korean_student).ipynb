{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Colabì„ í™œìš©í•œ deep learning model inference\n",
        "\n",
        "*   transformer model\n",
        "*   BERT, GPT, ì´ë¯¸ì§€ ë¶„ë¥˜ ë° ì¸ì‹ ëª¨ë¸ ë“±ì˜ ê¸°ë°˜\n",
        "\n",
        "\n",
        "- https://colab.research.google.com/github/huggingface/notebooks/blob/main/transformers_doc/en/pytorch/translation.ipynb"
      ],
      "metadata": {
        "id": "DYJQwQ2Ruq1-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pWOVrrk8L1B_"
      },
      "outputs": [],
      "source": [
        "# Transformers ì„¤ì¹˜ ë°©ë²•\n",
        "! pip install transformers datasets evaluate sacrebleu"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0fgQlUhhL1CB"
      },
      "source": [
        "# ë²ˆì—­[[translation]]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-zkXj606L1CC"
      },
      "source": [
        "ë²ˆì—­ì€ í•œ ì–¸ì–´ë¡œ ëœ ì‹œí€€ìŠ¤ë¥¼ ë‹¤ë¥¸ ì–¸ì–´ë¡œ ë³€í™˜í•©ë‹ˆë‹¤. ë²ˆì—­ì´ë‚˜ ìš”ì•½ì€ ì…ë ¥ì„ ë°›ì•„ ì¼ë ¨ì˜ ì¶œë ¥ì„ ë°˜í™˜í•˜ëŠ” ê°•ë ¥í•œ í”„ë ˆì„ì›Œí¬ì¸ ì‹œí€€ìŠ¤-íˆ¬-ì‹œí€€ìŠ¤ ë¬¸ì œë¡œ êµ¬ì„±í•  ìˆ˜ ìˆëŠ” ëŒ€í‘œì ì¸ íƒœìŠ¤í¬ì…ë‹ˆë‹¤. ë²ˆì—­ ì‹œìŠ¤í…œì€ ì¼ë°˜ì ìœ¼ë¡œ ë‹¤ë¥¸ ì–¸ì–´ë¡œ ëœ í…ìŠ¤íŠ¸ ê°„ì˜ ë²ˆì—­ì— ì‚¬ìš©ë˜ì§€ë§Œ, ìŒì„± ê°„ì˜ í†µì—­ì´ë‚˜ í…ìŠ¤íŠ¸-ìŒì„± ë˜ëŠ” ìŒì„±-í…ìŠ¤íŠ¸ì™€ ê°™ì€ ì¡°í•©ì—ë„ ì‚¬ìš©ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
        "\n",
        "í•™ìŠµí•  ë‚´ìš©ì€:\n",
        "\n",
        "1. ì˜ì–´ í…ìŠ¤íŠ¸ë¥¼ í”„ë‘ìŠ¤ì–´ë¡œ ë²ˆì—­í•˜ê¸° ìœ„í•´ [T5](https://huggingface.co/t5-small) ëª¨ë¸ì„ OPUS Books ë°ì´í„°ì„¸íŠ¸ì˜ ì˜ì–´-í”„ë‘ìŠ¤ì–´ í•˜ìœ„ ì§‘í•©ìœ¼ë¡œ íŒŒì¸íŠœë‹í•˜ëŠ” ë°©ë²•ê³¼\n",
        "2. íŒŒì¸íŠœë‹ëœ ëª¨ë¸ì„ ì¶”ë¡ ì— ì‚¬ìš©í•˜ëŠ” ë°©ë²•ì…ë‹ˆë‹¤.\n",
        "\n",
        "<Tip>\n",
        "ì´ íƒœìŠ¤í¬ ê°€ì´ë“œëŠ” ì•„ë˜ ëª¨ë¸ ì•„í‚¤í…ì²˜ì—ë„ ì‘ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
        "\n",
        "<!--This tip is automatically generated by `make fix-copies`, do not fill manually!-->\n",
        "\n",
        "[BART](https://huggingface.co/docs/transformers/main/ko/tasks/../model_doc/bart), [BigBird-Pegasus](https://huggingface.co/docs/transformers/main/ko/tasks/../model_doc/bigbird_pegasus), [Blenderbot](https://huggingface.co/docs/transformers/main/ko/tasks/../model_doc/blenderbot), [BlenderbotSmall](https://huggingface.co/docs/transformers/main/ko/tasks/../model_doc/blenderbot-small), [Encoder decoder](https://huggingface.co/docs/transformers/main/ko/tasks/../model_doc/encoder-decoder), [FairSeq Machine-Translation](https://huggingface.co/docs/transformers/main/ko/tasks/../model_doc/fsmt), [GPTSAN-japanese](https://huggingface.co/docs/transformers/main/ko/tasks/../model_doc/gptsan-japanese), [LED](https://huggingface.co/docs/transformers/main/ko/tasks/../model_doc/led), [LongT5](https://huggingface.co/docs/transformers/main/ko/tasks/../model_doc/longt5), [M2M100](https://huggingface.co/docs/transformers/main/ko/tasks/../model_doc/m2m_100), [Marian](https://huggingface.co/docs/transformers/main/ko/tasks/../model_doc/marian), [mBART](https://huggingface.co/docs/transformers/main/ko/tasks/../model_doc/mbart), [MT5](https://huggingface.co/docs/transformers/main/ko/tasks/../model_doc/mt5), [MVP](https://huggingface.co/docs/transformers/main/ko/tasks/../model_doc/mvp), [NLLB](https://huggingface.co/docs/transformers/main/ko/tasks/../model_doc/nllb), [NLLB-MOE](https://huggingface.co/docs/transformers/main/ko/tasks/../model_doc/nllb-moe), [Pegasus](https://huggingface.co/docs/transformers/main/ko/tasks/../model_doc/pegasus), [PEGASUS-X](https://huggingface.co/docs/transformers/main/ko/tasks/../model_doc/pegasus_x), [PLBart](https://huggingface.co/docs/transformers/main/ko/tasks/../model_doc/plbart), [ProphetNet](https://huggingface.co/docs/transformers/main/ko/tasks/../model_doc/prophetnet), [SwitchTransformers](https://huggingface.co/docs/transformers/main/ko/tasks/../model_doc/switch_transformers), [T5](https://huggingface.co/docs/transformers/main/ko/tasks/../model_doc/t5), [XLM-ProphetNet](https://huggingface.co/docs/transformers/main/ko/tasks/../model_doc/xlm-prophetnet)\n",
        "\n",
        "<!--End of the generated tip-->\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-HyTjL0LL1CD"
      },
      "source": [
        "## OPUS Books ë°ì´í„°ì„¸íŠ¸ ê°€ì ¸ì˜¤ê¸°[[load-opus-books-dataset]]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M0mKFktZL1CD"
      },
      "source": [
        "ë¨¼ì € ğŸ¤— Datasets ë¼ì´ë¸ŒëŸ¬ë¦¬ì—ì„œ [OPUS Books](https://huggingface.co/datasets/opus_books) ë°ì´í„°ì„¸íŠ¸ì˜ ì˜ì–´-í”„ë‘ìŠ¤ì–´ í•˜ìœ„ ì§‘í•©ì„ ê°€ì ¸ì˜¤ì„¸ìš”."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fonhYrl4L1CD"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "books = load_dataset(\"opus_books\", \"en-fr\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4fbJD73HL1CE"
      },
      "source": [
        "ë°ì´í„°ì„¸íŠ¸ë¥¼ `train_test_split` ë©”ì„œë“œë¥¼ ì‚¬ìš©í•˜ì—¬ í›ˆë ¨ ë° í…ŒìŠ¤íŠ¸ ë°ì´í„°ë¡œ ë¶„í• í•˜ì„¸ìš”."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zNAq_2d5L1CE"
      },
      "outputs": [],
      "source": [
        "books = books[\"train\"].train_test_split(test_size=0.001) # 0.2 -> 0.001"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bbdGI_GpL1CE"
      },
      "source": [
        "í›ˆë ¨ ë°ì´í„°ì—ì„œ ì˜ˆì‹œë¥¼ ì‚´í´ë³¼ê¹Œìš”?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vRTwEN_vL1CE"
      },
      "outputs": [],
      "source": [
        "books[\"train\"][123]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZXzPghC4L1CE"
      },
      "source": [
        "ë°˜í™˜ëœ ë”•ì…”ë„ˆë¦¬ì˜ `translation` í‚¤ê°€ í…ìŠ¤íŠ¸ì˜ ì˜ì–´, í”„ë‘ìŠ¤ì–´ ë²„ì „ì„ í¬í•¨í•˜ê³  ìˆëŠ” ê²ƒì„ ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xWt9ghjDL1CE"
      },
      "source": [
        "## ì „ì²˜ë¦¬[[preprocess]]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iWDCY-vaL1CF"
      },
      "source": [
        "ë‹¤ìŒ ë‹¨ê³„ë¡œ ì˜ì–´-í”„ë‘ìŠ¤ì–´ ìŒì„ ì²˜ë¦¬í•˜ê¸° ìœ„í•´ T5 í† í¬ë‚˜ì´ì €ë¥¼ ê°€ì ¸ì˜¤ì„¸ìš”."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fexZXNFtL1CF"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "checkpoint = \"t5-small\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xaGFxGKuL1CF"
      },
      "source": [
        "ë§Œë“¤ ì „ì²˜ë¦¬ í•¨ìˆ˜ëŠ” ì•„ë˜ ìš”êµ¬ì‚¬í•­ì„ ì¶©ì¡±í•´ì•¼ í•©ë‹ˆë‹¤:\n",
        "\n",
        "1. T5ê°€ ë²ˆì—­ íƒœìŠ¤í¬ì„ì„ ì¸ì§€í•  ìˆ˜ ìˆë„ë¡ ì…ë ¥ ì•ì— í”„ë¡¬í”„íŠ¸ë¥¼ ì¶”ê°€í•˜ì„¸ìš”. ì—¬ëŸ¬ NLP íƒœìŠ¤í¬ë¥¼ í•  ìˆ˜ ìˆëŠ” ëª¨ë¸ ì¤‘ ì¼ë¶€ëŠ” ì´ë ‡ê²Œ íƒœìŠ¤í¬ í”„ë¡¬í”„íŠ¸ë¥¼ ë¯¸ë¦¬ ì¤˜ì•¼í•©ë‹ˆë‹¤.\n",
        "2. ~ì›ì–´(ì˜ì–´)ê³¼ ë²ˆì—­ì–´(í”„ë‘ìŠ¤ì–´)ë¥¼ ë³„ë„ë¡œ í† í°í™”í•˜ì„¸ìš”. ì˜ì–´ ì–´íœ˜ë¡œ ì‚¬ì „ í•™ìŠµëœ í† í¬ë‚˜ì´ì €ë¡œ í”„ë‘ìŠ¤ì–´ í…ìŠ¤íŠ¸ë¥¼ í† í°í™”í•  ìˆ˜ëŠ” ì—†ê¸° ë•Œë¬¸ì…ë‹ˆë‹¤.~\n",
        "3. `max_length` ë§¤ê°œë³€ìˆ˜ë¡œ ì„¤ì •í•œ ìµœëŒ€ ê¸¸ì´ë³´ë‹¤ ê¸¸ì§€ ì•Šë„ë¡ ì‹œí€€ìŠ¤ë¥¼ truncateí•˜ì„¸ìš”."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "khY8qB7pL1CF"
      },
      "outputs": [],
      "source": [
        "source_lang = \"en\"\n",
        "target_lang = \"es\"\n",
        "prefix = \"translate English to French: \"\n",
        "\n",
        "\n",
        "def preprocess_function(examples):\n",
        "    inputs = [prefix + example[source_lang] for example in examples[\"translation\"]]\n",
        "    targets = [example[target_lang] for example in examples[\"translation\"]]\n",
        "    model_inputs = tokenizer(inputs, text_target=targets, max_length=128, truncation=True)\n",
        "    return model_inputs"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "truncation : max_length 128ì´ìƒì€ ë²„ë¦¼"
      ],
      "metadata": {
        "id": "-wgpC253ToYW"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E_ORsEHzL1CF"
      },
      "source": [
        "ì „ì²´ ë°ì´í„°ì„¸íŠ¸ì— ì „ì²˜ë¦¬ í•¨ìˆ˜ë¥¼ ì ìš©í•˜ë ¤ë©´ ğŸ¤— Datasetsì˜ `map` ë©”ì„œë“œë¥¼ ì‚¬ìš©í•˜ì„¸ìš”. `map` í•¨ìˆ˜ì˜ ì†ë„ë¥¼ ë†’ì´ë ¤ë©´ `batched=True`ë¥¼ ì„¤ì •í•˜ì—¬ ë°ì´í„°ì„¸íŠ¸ì˜ ì—¬ëŸ¬ ìš”ì†Œë¥¼ í•œ ë²ˆì— ì²˜ë¦¬í•˜ëŠ” ë°©ë²•ì´ ìˆìŠµë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i6B8v4V2L1CF"
      },
      "outputs": [],
      "source": [
        "tokenized_books = books.map(preprocess_function, batched=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dmIfq37SL1CF"
      },
      "source": [
        "ì´ì œ `DataCollatorForSeq2Seq`ë¥¼ ì‚¬ìš©í•˜ì—¬ í•™ìŠµìš© ë°°ì¹˜ë¥¼ ìƒì„±í•©ë‹ˆë‹¤. ë°ì´í„°ì„¸íŠ¸ì˜ ìµœëŒ€ ê¸¸ì´ë¡œ ì „ë¶€ë¥¼ paddingí•˜ëŠ” ëŒ€ì‹ , ë°ì´í„° ì •ë ¬ ì¤‘ ê° ë°°ì¹˜ì˜ ìµœëŒ€ ê¸¸ì´ë¡œ ë¬¸ì¥ì„ *ë™ì ìœ¼ë¡œ padding*í•˜ëŠ” ê²ƒì´ ë” íš¨ìœ¨ì ì…ë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K5ccBqRjL1CF"
      },
      "outputs": [],
      "source": [
        "from transformers import DataCollatorForSeq2Seq\n",
        "\n",
        "data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=checkpoint)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EBFARR3BL1CF"
      },
      "source": [
        "## í‰ê°€[[evalulate]]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ur7ZPAsbL1CF"
      },
      "source": [
        "í›ˆë ¨ ì¤‘ì— ë©”íŠ¸ë¦­ì„ í¬í•¨í•˜ë©´ ëª¨ë¸ì˜ ì„±ëŠ¥ì„ í‰ê°€í•˜ëŠ” ë° ë„ì›€ì´ ë©ë‹ˆë‹¤. ğŸ¤— [Evaluate](https://huggingface.co/docs/evaluate/index) ë¼ì´ë¸ŒëŸ¬ë¦¬ë¡œ í‰ê°€ ë°©ë²•(evaluation method)ì„ ë¹ ë¥´ê²Œ ê°€ì ¸ì˜¬ ìˆ˜ ìˆìŠµë‹ˆë‹¤. í˜„ì¬ íƒœìŠ¤í¬ì— ì í•©í•œ SacreBLEU ë©”íŠ¸ë¦­ì„ ê°€ì ¸ì˜¤ì„¸ìš”. (ë©”íŠ¸ë¦­ì„ ê°€ì ¸ì˜¤ê³  ê³„ì‚°í•˜ëŠ” ë°©ë²•ì— ëŒ€í•´ ìì„¸íˆ ì•Œì•„ë³´ë ¤ë©´ ğŸ¤— Evaluate [ë‘˜ëŸ¬ë³´ê¸°](https://huggingface.co/docs/evaluate/a_quick_tour)ë¥¼ ì°¸ì¡°í•˜ì„¸ìš”):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UUivy-YcL1CF"
      },
      "outputs": [],
      "source": [
        "import evaluate\n",
        "\n",
        "metric = evaluate.load(\"sacrebleu\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZDVjunulL1CF"
      },
      "source": [
        "SacreBLEU ì ìˆ˜ë¥¼ ê³„ì‚°í•˜ëŠ” í•¨ìˆ˜ë¥¼ ìƒì„±í•˜ì„¸ìš”.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sgpl3aAzL1CF"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "\n",
        "def postprocess_text(preds, labels):\n",
        "    preds = [pred.strip() for pred in preds]\n",
        "    labels = [[label.strip()] for label in labels]\n",
        "\n",
        "    return preds, labels\n",
        "\n",
        "\n",
        "def compute_metrics(eval_preds):\n",
        "    preds, labels = eval_preds\n",
        "    if isinstance(preds, tuple):\n",
        "        preds = preds[0]\n",
        "    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
        "\n",
        "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
        "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
        "\n",
        "    decoded_preds, decoded_labels = postprocess_text(decoded_preds, decoded_labels)\n",
        "\n",
        "    result = metric.compute(predictions=decoded_preds, references=decoded_labels)\n",
        "    result = {\"bleu\": result[\"score\"]}\n",
        "\n",
        "    prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in preds]\n",
        "    result[\"gen_len\"] = np.mean(prediction_lens)\n",
        "    result = {k: round(v, 4) for k, v in result.items()}\n",
        "    return result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dJjQ6dSJL1CF"
      },
      "source": [
        "ì´ì œ `compute_metrics` í•¨ìˆ˜ëŠ” ì¤€ë¹„ë˜ì—ˆê³ , í›ˆë ¨ ê³¼ì •ì„ ì„¤ì •í•  ë•Œ ë‹¤ì‹œ ì‚´í´ë³¼ ì˜ˆì •ì…ë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rfWVJw9AL1CG"
      },
      "source": [
        "## í›ˆë ¨[[train]]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2_eI6kROL1CG"
      },
      "source": [
        "<Tip>\n",
        "\n",
        "`Trainer`ë¡œ ëª¨ë¸ì„ íŒŒì¸íŠœë‹í•˜ëŠ” ë°©ë²•ì— ìµìˆ™í•˜ì§€ ì•Šë‹¤ë©´ [ì—¬ê¸°](https://huggingface.co/docs/transformers/main/ko/tasks/../training#train-with-pytorch-trainer)ì—ì„œ ê¸°ë³¸ íŠœí† ë¦¬ì–¼ì„ ì‚´í´ë³´ì‹œê¸° ë°”ëë‹ˆë‹¤!\n",
        "\n",
        "</Tip>\n",
        "\n",
        "ëª¨ë¸ì„ í›ˆë ¨ì‹œí‚¬ ì¤€ë¹„ê°€ ë˜ì—ˆêµ°ìš”! `AutoModelForSeq2SeqLM`ìœ¼ë¡œ T5ë¥¼ ë¡œë“œí•˜ì„¸ìš”:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3LARZxbIL1CG"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoModelForSeq2SeqLM, Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
        "\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(checkpoint)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9glYSTRHL1CG"
      },
      "source": [
        "ì´ì œ ì„¸ ë‹¨ê³„ë§Œ ê±°ì¹˜ë©´ ëì…ë‹ˆë‹¤:\n",
        "\n",
        "1. `Seq2SeqTrainingArguments`ì—ì„œ í›ˆë ¨ í•˜ì´í¼íŒŒë¼ë¯¸í„°ë¥¼ ì •ì˜í•˜ì„¸ìš”. ìœ ì¼í•œ í•„ìˆ˜ ë§¤ê°œë³€ìˆ˜ëŠ” ëª¨ë¸ì„ ì €ì¥í•  ìœ„ì¹˜ì¸ `output_dir`ì…ë‹ˆë‹¤. ëª¨ë¸ì„ Hubì— í‘¸ì‹œí•˜ê¸° ìœ„í•´ `push_to_hub=True`ë¡œ ì„¤ì •í•˜ì„¸ìš”. (ëª¨ë¸ì„ ì—…ë¡œë“œí•˜ë ¤ë©´ Hugging Faceì— ë¡œê·¸ì¸í•´ì•¼ í•©ë‹ˆë‹¤.) `Trainer`ëŠ” ì—í­ì´ ëë‚ ë•Œë§ˆë‹¤ SacreBLEU ë©”íŠ¸ë¦­ì„ í‰ê°€í•˜ê³  í›ˆë ¨ ì²´í¬í¬ì¸íŠ¸ë¥¼ ì €ì¥í•©ë‹ˆë‹¤.\n",
        "2. `Seq2SeqTrainer`ì— í›ˆë ¨ ì¸ìˆ˜ë¥¼ ì „ë‹¬í•˜ì„¸ìš”. ëª¨ë¸, ë°ì´í„° ì„¸íŠ¸, í† í¬ë‚˜ì´ì €, data collator ë° `compute_metrics` í•¨ìˆ˜ë„ ë©ë‹¬ì•„ ì „ë‹¬í•´ì•¼ í•©ë‹ˆë‹¤.\n",
        "3. `train()`ì„ í˜¸ì¶œí•˜ì—¬ ëª¨ë¸ì„ íŒŒì¸íŠœë‹í•˜ì„¸ìš”."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M8KRpXxnL1CG"
      },
      "outputs": [],
      "source": [
        "training_args = Seq2SeqTrainingArguments(\n",
        "    output_dir=\"my_awesome_opus_books_model\",\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=16,\n",
        "    weight_decay=0.01,\n",
        "    save_total_limit=3,\n",
        "    num_train_epochs=2,\n",
        "    max_steps=10,                       # gpu ê³„ì‚°ëŸ‰ì„ ì¤„ì´ê¸° ìœ„í•´ì„œ ì¶”ê°€\n",
        "    predict_with_generate=True,\n",
        "    fp16=True,\n",
        "    push_to_hub=False,\n",
        ")\n",
        "\n",
        "trainer = Seq2SeqTrainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_books[\"train\"],\n",
        "    eval_dataset=tokenized_books[\"test\"],\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=data_collator,\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "\n",
        "trainer.train()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fOElWTSeL1CG"
      },
      "source": [
        "## ì¶”ë¡ [[inference]]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "36gny1iiL1CG"
      },
      "source": [
        "ì´ì œ ëª¨ë¸ì„ íŒŒì¸íŠœë‹í–ˆìœ¼ë‹ˆ ì¶”ë¡ ì— ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤!\n",
        "\n",
        "ë‹¤ë¥¸ ì–¸ì–´ë¡œ ë²ˆì—­í•˜ê³  ì‹¶ì€ í…ìŠ¤íŠ¸ë¥¼ ì¨ë³´ì„¸ìš”. T5ì˜ ê²½ìš° ì›í•˜ëŠ” íƒœìŠ¤í¬ë¥¼ ì…ë ¥ì˜ ì ‘ë‘ì‚¬ë¡œ ì¶”ê°€í•´ì•¼ í•©ë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´ ì˜ì–´ì—ì„œ í”„ë‘ìŠ¤ì–´ë¡œ ë²ˆì—­í•˜ëŠ” ê²½ìš°, ì•„ë˜ì™€ ê°™ì€ ì ‘ë‘ì‚¬ê°€ ì¶”ê°€ë©ë‹ˆë‹¤:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "43SWGEcWL1CG"
      },
      "outputs": [],
      "source": [
        "# text = \"translate English to French: Legumes share resources with nitrogen-fixing bacteria.\"\n",
        "text = \"translate English to French: Would you like a cup of coffee?\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "í…ìŠ¤íŠ¸ë¥¼ í† í°í™”í•˜ê³  `input_ids`ë¥¼ PyTorch í…ì„œë¡œ ë°˜í™˜í•˜ì„¸ìš”:  "
      ],
      "metadata": {
        "id": "FH9cZp9N2QnM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ydfDuORqL1CK"
      },
      "outputs": [],
      "source": [
        "# inputs = tokenizer(text, return_tensors=\"pt\").input_ids\n",
        "inputs = tokenizer(text, return_tensors=\"pt\").input_ids.to(\"cuda:0\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(inputs)"
      ],
      "metadata": {
        "id": "V9DJG9sl5Jw_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "tensor : ìë£Œí˜• ì¤‘ í•˜ë‚˜ (list, set, tuple, dic... str, num)  \n",
        "í–‰ë ¬(matrix)ì„ n ì°¨ì› í•œê±°"
      ],
      "metadata": {
        "id": "FZrouaQ_szqb"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hrxn-Wn_L1CK"
      },
      "source": [
        "`generate()` ë©”ì„œë“œë¡œ ë²ˆì—­ì„ ìƒì„±í•˜ì„¸ìš”. ë‹¤ì–‘í•œ í…ìŠ¤íŠ¸ ìƒì„± ì „ëµ ë° ìƒì„±ì„ ì œì–´í•˜ê¸° ìœ„í•œ ë§¤ê°œë³€ìˆ˜ì— ëŒ€í•œ ìì„¸í•œ ë‚´ìš©ì€ [Text Generation](https://huggingface.co/docs/transformers/main/ko/tasks/../main_classes/text_generation) APIë¥¼ ì‚´í´ë³´ì‹œê¸° ë°”ëë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SylTzmBAL1CK"
      },
      "outputs": [],
      "source": [
        "outputs = model.generate(inputs, max_new_tokens=40, do_sample=True, top_k=30, top_p=0.95)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(outputs)"
      ],
      "metadata": {
        "id": "Ses04sRK5cSP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c7GdeFz5L1CK"
      },
      "source": [
        "ìƒì„±ëœ í† í° IDë“¤ì„ ë‹¤ì‹œ í…ìŠ¤íŠ¸ë¡œ ë””ì½”ë”©í•˜ì„¸ìš”:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n_5M11jpL1CK"
      },
      "outputs": [],
      "source": [
        "tokenizer.decode(outputs[0], skip_special_tokens=True)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "collapsed_sections": [
        "0fgQlUhhL1CB",
        "-HyTjL0LL1CD",
        "xWt9ghjDL1CE",
        "EBFARR3BL1CF",
        "rfWVJw9AL1CG",
        "fOElWTSeL1CG"
      ]
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}